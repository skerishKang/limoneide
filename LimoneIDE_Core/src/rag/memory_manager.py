"""
ðŸ‹ LimoneIDE Memory Manager
êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
"""

import json
import time
from typing import Dict, Any, List, Optional
from datetime import datetime

class MemoryManager:
    """
    LimoneIDE ë©”ëª¨ë¦¬ ê´€ë¦¬ìž
    - ëª¨ë“  ëŒ€í™” ìžë™ ì €ìž¥
    - ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ
    - ê°œì¸ ë§žì¶¤ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
    """
    
    def __init__(self):
        self.conversations = []
        self.user_profiles = {}
        self.search_index = {}

    async def save_conversation(self, user_id: str, user_message: str, ai_response: str, metadata: Dict[str, Any] = {}) -> bool:
        """
        ëŒ€í™” ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ì €ìž¥
        """
        try:
            conversation = {
                "id": f"conv_{int(time.time())}",
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "user_message": user_message,
                "ai_response": ai_response,
                "metadata": metadata,
                "tags": self.extract_tags(user_message, ai_response)
            }
            
            self.conversations.append(conversation)
            
            # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            self.update_search_index(conversation)
            
            # ì‚¬ìš©ìž í”„ë¡œí•„ ì—…ë°ì´íŠ¸
            self.update_user_profile(user_id, conversation)
            
            return True
            
        except Exception as e:
            print(f"ëŒ€í™” ì €ìž¥ ì‹¤íŒ¨: {e}")
            return False

    def extract_tags(self, user_message: str, ai_response: str) -> List[str]:
        """
        ëŒ€í™”ì—ì„œ íƒœê·¸ ì¶”ì¶œ (í”„ë¡œí† íƒ€ìž…)
        """
        tags = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì¶”ì¶œ
        keywords = {
            "website": ["ì›¹ì‚¬ì´íŠ¸", "ì‚¬ì´íŠ¸", "ë§Œë“¤ì–´ì¤˜", "ìƒì„±"],
            "automation": ["ìžë™í™”", "ë§¤ì¼", "ë§¤ì£¼", "ì •ê¸°"],
            "analysis": ["ë¶„ì„", "í†µê³„", "ë°ì´í„°", "ë¦¬í¬íŠ¸"],
            "content": ["ê¸€", "ì½˜í…ì¸ ", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤"],
            "ecommerce": ["ì‡¼í•‘ëª°", "ìƒí’ˆ", "ê²°ì œ", "ì£¼ë¬¸"],
            "blog": ["ë¸”ë¡œê·¸", "ê¸€ì“°ê¸°", "í¬ìŠ¤íŠ¸", "ì¹´í…Œê³ ë¦¬"]
        }
        
        combined_text = (user_message + " " + ai_response).lower()
        
        for category, words in keywords.items():
            if any(word in combined_text for word in words):
                tags.append(category)
        
        return tags

    def update_search_index(self, conversation: Dict[str, Any]):
        """
        ê²€ìƒ‰ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        """
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¸ë±ì‹± (ì‹¤ì œë¡œëŠ” ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©)
        text = f"{conversation['user_message']} {conversation['ai_response']}"
        words = text.lower().split()
        
        for word in words:
            if len(word) > 2:  # 2ê¸€ìž ì´ìƒë§Œ ì¸ë±ì‹±
                if word not in self.search_index:
                    self.search_index[word] = []
                self.search_index[word].append(conversation['id'])

    def update_user_profile(self, user_id: str, conversation: Dict[str, Any]):
        """
        ì‚¬ìš©ìž í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        """
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = {
                "conversation_count": 0,
                "favorite_topics": {},
                "last_active": None,
                "preferences": {}
            }
        
        profile = self.user_profiles[user_id]
        profile["conversation_count"] += 1
        profile["last_active"] = conversation["timestamp"]
        
        # ì£¼ì œë³„ ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
        for tag in conversation["tags"]:
            if tag not in profile["favorite_topics"]:
                profile["favorite_topics"][tag] = 0
            profile["favorite_topics"][tag] += 1

    async def search_conversations(self, query: str, user_id: str = "", limit: int = 10) -> List[Dict[str, Any]]:
        """
        ê³¼ê±° ëŒ€í™” ê²€ìƒ‰
        """
        try:
            query_words = query.lower().split()
            relevant_conversations = []
            
            for word in query_words:
                if word in self.search_index:
                    conv_ids = self.search_index[word]
                    for conv_id in conv_ids:
                        conversation = next((c for c in self.conversations if c["id"] == conv_id), None)
                        if conversation and (user_id == "" or conversation["user_id"] == user_id):
                            if conversation not in relevant_conversations:
                                relevant_conversations.append(conversation)
            
            # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (íƒœê·¸ ë§¤ì¹­ ê°œìˆ˜ ê¸°ì¤€)
            relevant_conversations.sort(
                key=lambda x: sum(1 for word in query_words if word in x["user_message"].lower() or word in x["ai_response"].lower()),
                reverse=True
            )
            
            return relevant_conversations[:limit]
            
        except Exception as e:
            print(f"ëŒ€í™” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def get_user_context(self, user_id: str, limit: int = 5) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìžë³„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë°˜í™˜
        """
        if user_id not in self.user_profiles:
            return {}
        
        profile = self.user_profiles[user_id]
        
        # ìµœê·¼ ëŒ€í™”ë“¤
        recent_conversations = [
            c for c in self.conversations 
            if c["user_id"] == user_id
        ][-limit:]
        
        # ì„ í˜¸ ì£¼ì œ
        favorite_topics = sorted(
            profile["favorite_topics"].items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        
        return {
            "user_id": user_id,
            "conversation_count": profile["conversation_count"],
            "last_active": profile["last_active"],
            "favorite_topics": [topic for topic, count in favorite_topics],
            "recent_conversations": recent_conversations,
            "preferences": profile["preferences"]
        }

    async def get_project_history(self, user_id: str, project_keywords: List[str]) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • í”„ë¡œì íŠ¸ ê´€ë ¨ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ë°˜í™˜
        """
        try:
            project_conversations = []
            
            for conversation in self.conversations:
                if conversation["user_id"] == user_id:
                    text = f"{conversation['user_message']} {conversation['ai_response']}"
                    if any(keyword.lower() in text.lower() for keyword in project_keywords):
                        project_conversations.append(conversation)
            
            return project_conversations
            
        except Exception as e:
            print(f"í”„ë¡œì íŠ¸ ížˆìŠ¤í† ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def export_conversations(self, user_id: str = "") -> str:
        """
        ëŒ€í™” ë‚´ë³´ë‚´ê¸° (JSON í˜•ì‹)
        """
        try:
            if user_id:
                user_conversations = [c for c in self.conversations if c["user_id"] == user_id]
            else:
                user_conversations = self.conversations
            
            export_data = {
                "export_time": datetime.now().isoformat(),
                "conversations": user_conversations,
                "user_profiles": self.user_profiles if user_id == "" else {user_id: self.user_profiles.get(user_id, {})}
            }
            
            return json.dumps(export_data, ensure_ascii=False, indent=2)
            
        except Exception as e:
            print(f"ëŒ€í™” ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return ""

    def get_statistics(self) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ì‚¬ìš© í†µê³„
        """
        total_conversations = len(self.conversations)
        unique_users = len(set(c["user_id"] for c in self.conversations))
        
        # íƒœê·¸ë³„ í†µê³„
        tag_counts = {}
        for conversation in self.conversations:
            for tag in conversation["tags"]:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        return {
            "total_conversations": total_conversations,
            "unique_users": unique_users,
            "tag_distribution": tag_counts,
            "search_index_size": len(self.search_index),
            "memory_size_mb": len(json.dumps(self.conversations)) / (1024 * 1024)
        } 